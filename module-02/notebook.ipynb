{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T05:41:12.530314Z",
     "iopub.status.busy": "2024-07-11T05:41:12.529942Z",
     "iopub.status.idle": "2024-07-11T05:41:13.273309Z",
     "shell.execute_reply": "2024-07-11T05:41:13.272599Z",
     "shell.execute_reply.started": "2024-07-11T05:41:12.530285Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-11 05:41:13--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3832 (3.7K) [text/plain]\n",
      "Saving to: ‘minsearch.py’\n",
      "\n",
      "minsearch.py        100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-07-11 05:41:13 (61.3 MB/s) - ‘minsearch.py’ saved [3832/3832]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T05:41:14.036046Z",
     "iopub.status.busy": "2024-07-11T05:41:14.035644Z",
     "iopub.status.idle": "2024-07-11T05:41:21.677287Z",
     "shell.execute_reply": "2024-07-11T05:41:21.676569Z",
     "shell.execute_reply.started": "2024-07-11T05:41:14.036014Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import json\n",
    "import minsearch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T05:41:21.679704Z",
     "iopub.status.busy": "2024-07-11T05:41:21.678857Z",
     "iopub.status.idle": "2024-07-11T05:41:21.687177Z",
     "shell.execute_reply": "2024-07-11T05:41:21.686491Z",
     "shell.execute_reply.started": "2024-07-11T05:41:21.679665Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/run/cache/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['HF_HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T05:41:42.652006Z",
     "iopub.status.busy": "2024-07-11T05:41:42.651609Z",
     "iopub.status.idle": "2024-07-11T05:41:43.280856Z",
     "shell.execute_reply": "2024-07-11T05:41:43.279975Z",
     "shell.execute_reply.started": "2024-07-11T05:41:42.651977Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         100G   36G   65G  36% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "tmpfs           7.7G     0  7.7G   0% /sys/fs/cgroup\n",
      "/dev/nvme0n1p1  100G   36G   65G  36% /run\n",
      "tmpfs            14G     0   14G   0% /dev/shm\n",
      "/dev/nvme2n1    2.0G  130M  1.8G   7% /home/jovyan\n",
      "tmpfs            14G  120K   14G   1% /home/jovyan/.saturn\n",
      "tmpfs            14G   12K   14G   1% /run/secrets/kubernetes.io/serviceaccount\n",
      "tmpfs           7.7G   12K  7.7G   1% /proc/driver/nvidia\n",
      "tmpfs           7.7G  3.3M  7.7G   1% /run/nvidia-persistenced/socket\n",
      "tmpfs           7.7G     0  7.7G   0% /proc/acpi\n",
      "tmpfs           7.7G     0  7.7G   0% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T05:42:17.601762Z",
     "iopub.status.busy": "2024-07-11T05:42:17.601357Z",
     "iopub.status.idle": "2024-07-11T05:44:47.446332Z",
     "shell.execute_reply": "2024-07-11T05:44:47.445752Z",
     "shell.execute_reply.started": "2024-07-11T05:42:17.601733Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de7553f2e944638b5466ffdbce5a56a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5feed778972c48919be8cfd71ede7e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31022912720460d84b2d539fcbf892d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0208f400d5b34465b32ecd31f3e71aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07b55f5e6b948898821941100655786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8e14b64c3c467e895ddc117a8131cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/53.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7937cd9a56e54a9c967960d9276904c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b9f82fd4fb405997a7c8c26b732907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.45G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026ec58798964eb3a3a206612bcf9bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b7b002ceb9458bb8d9e66747d6e518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a2c919768d4a72a4e34d16badb6978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xl\", device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrivel and Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T05:44:51.981922Z",
     "iopub.status.busy": "2024-07-11T05:44:51.981543Z",
     "iopub.status.idle": "2024-07-11T05:44:52.850762Z",
     "shell.execute_reply": "2024-07-11T05:44:52.849880Z",
     "shell.execute_reply.started": "2024-07-11T05:44:51.981893Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-11 05:44:52--  https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/documents.json\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 658332 (643K) [text/plain]\n",
      "Saving to: ‘documents.json’\n",
      "\n",
      "documents.json      100%[===================>] 642.90K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2024-07-11 05:44:52 (62.8 MB/s) - ‘documents.json’ saved [658332/658332]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/documents.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T05:44:55.227902Z",
     "iopub.status.busy": "2024-07-11T05:44:55.227483Z",
     "iopub.status.idle": "2024-07-11T05:44:55.235465Z",
     "shell.execute_reply": "2024-07-11T05:44:55.234802Z",
     "shell.execute_reply.started": "2024-07-11T05:44:55.227871Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('documents.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T05:44:57.533904Z",
     "iopub.status.busy": "2024-07-11T05:44:57.533521Z",
     "iopub.status.idle": "2024-07-11T05:44:57.538860Z",
     "shell.execute_reply": "2024-07-11T05:44:57.538020Z",
     "shell.execute_reply.started": "2024-07-11T05:44:57.533877Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\", 'section': 'General course-related questions', 'question': 'Course - When will the course start?', 'course': 'data-engineering-zoomcamp'}\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)\n",
    "\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T05:45:02.250810Z",
     "iopub.status.busy": "2024-07-11T05:45:02.250408Z",
     "iopub.status.idle": "2024-07-11T05:45:02.254713Z",
     "shell.execute_reply": "2024-07-11T05:45:02.253956Z",
     "shell.execute_reply.started": "2024-07-11T05:45:02.250773Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T05:45:02.641011Z",
     "iopub.status.busy": "2024-07-11T05:45:02.640627Z",
     "iopub.status.idle": "2024-07-11T05:45:02.755452Z",
     "shell.execute_reply": "2024-07-11T05:45:02.754556Z",
     "shell.execute_reply.started": "2024-07-11T05:45:02.640982Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7f5157162f10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The RAG Flow Cleaning and Modularizing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T05:45:04.689078Z",
     "iopub.status.busy": "2024-07-11T05:45:04.688678Z",
     "iopub.status.idle": "2024-07-11T05:45:04.693622Z",
     "shell.execute_reply": "2024-07-11T05:45:04.692791Z",
     "shell.execute_reply.started": "2024-07-11T05:45:04.689049Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course':'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T05:45:05.034742Z",
     "iopub.status.busy": "2024-07-11T05:45:05.034355Z",
     "iopub.status.idle": "2024-07-11T05:45:05.039299Z",
     "shell.execute_reply": "2024-07-11T05:45:05.038631Z",
     "shell.execute_reply.started": "2024-07-11T05:45:05.034714Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = '''\n",
    "    You are a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database. \n",
    "    Use only facts from the CONTEXT when answering the QUESTION.\n",
    "    If the CONTEXT doesn't contain the answer, output NONE\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    \n",
    "    CONTEXT: {context}\n",
    "    \n",
    "    '''.strip()\n",
    "\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T05:45:07.087612Z",
     "iopub.status.busy": "2024-07-11T05:45:07.087207Z",
     "iopub.status.idle": "2024-07-11T05:45:07.092843Z",
     "shell.execute_reply": "2024-07-11T05:45:07.092155Z",
     "shell.execute_reply.started": "2024-07-11T05:45:07.087582Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def llm(prompt, generate_params=None):\n",
    "    if generate_params is None:\n",
    "        generate_params = {}\n",
    "\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_length=generate_params.get(\"max_length\", 100),\n",
    "        num_beams=generate_params.get(\"num_beams\", 5),\n",
    "        do_sample=generate_params.get(\"do_sample\", False),\n",
    "        temperature=generate_params.get(\"temperature\", 1.0),\n",
    "        top_k=generate_params.get(\"top_k\", 50),\n",
    "        top_p=generate_params.get(\"top_p\", 0.95),\n",
    "    )\n",
    "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T05:45:08.966603Z",
     "iopub.status.busy": "2024-07-11T05:45:08.966215Z",
     "iopub.status.idle": "2024-07-11T05:45:08.970445Z",
     "shell.execute_reply": "2024-07-11T05:45:08.969747Z",
     "shell.execute_reply.started": "2024-07-11T05:45:08.966575Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    results = search(query)\n",
    "    builded_prompt = build_prompt(query, results)\n",
    "    answer = llm(builded_prompt)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T05:45:10.092408Z",
     "iopub.status.busy": "2024-07-11T05:45:10.092022Z",
     "iopub.status.idle": "2024-07-11T05:45:17.679212Z",
     "shell.execute_reply": "2024-07-11T05:45:17.678374Z",
     "shell.execute_reply.started": "2024-07-11T05:45:10.092381Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (909 > 512). Running this sequence through the model will result in indexing errors\n",
      "/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:545: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, even if you don't register, you're still eligible to submit the homeworks. Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n"
     ]
    }
   ],
   "source": [
    "query = \"the course has already started. Can I still join?\"\n",
    "print(rag(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
