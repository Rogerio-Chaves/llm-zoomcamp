{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T02:44:50.777642Z",
     "iopub.status.busy": "2024-07-12T02:44:50.777261Z",
     "iopub.status.idle": "2024-07-12T02:44:52.126503Z",
     "shell.execute_reply": "2024-07-12T02:44:52.125676Z",
     "shell.execute_reply.started": "2024-07-12T02:44:50.777616Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-12 02:44:51--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3832 (3.7K) [text/plain]\n",
      "Saving to: ‘minsearch.py’\n",
      "\n",
      "minsearch.py        100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-07-12 02:44:52 (82.4 MB/s) - ‘minsearch.py’ saved [3832/3832]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm -f minsearch.py\n",
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T02:44:54.519306Z",
     "iopub.status.busy": "2024-07-12T02:44:54.518897Z",
     "iopub.status.idle": "2024-07-12T02:45:02.571904Z",
     "shell.execute_reply": "2024-07-12T02:45:02.571256Z",
     "shell.execute_reply.started": "2024-07-12T02:44:54.519277Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline \n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import json\n",
    "import minsearch\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T02:45:02.573956Z",
     "iopub.status.busy": "2024-07-12T02:45:02.573334Z",
     "iopub.status.idle": "2024-07-12T02:45:02.624946Z",
     "shell.execute_reply": "2024-07-12T02:45:02.624197Z",
     "shell.execute_reply.started": "2024-07-12T02:45:02.573919Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /run/cache/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login(token=os.environ['HF_TOKEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T03:14:46.156173Z",
     "iopub.status.busy": "2024-07-12T03:14:46.155786Z",
     "iopub.status.idle": "2024-07-12T03:18:26.265708Z",
     "shell.execute_reply": "2024-07-12T03:18:26.264956Z",
     "shell.execute_reply.started": "2024-07-12T03:14:46.156148Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08788b1d64f645e5a914fd930f7d7544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbcc80a05a64d929660dd984a0a0c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3459d3c6bb674782ad6f2becd5908e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2a4c2cb9984e109e3e370eac0ac1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f0d0dcdc7b4cbf93a61b0454bcc233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c70c50622b1a4af8832ae3316ecf453c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e50306de71f4d16bd6e5dcbe82d8d31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad31aa9add6d486699ba989eff0386ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5a333224f546dea75b9d93e48bc982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1a7e668aa74793b6bec02bd10723ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52b52721f424b4692684b27a4f68ae5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\", paddig_side=\"left\") \n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-v0.1\", device_map=\"auto\", load_in_4bit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrivel and Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T03:18:50.307744Z",
     "iopub.status.busy": "2024-07-12T03:18:50.307344Z",
     "iopub.status.idle": "2024-07-12T03:18:51.834170Z",
     "shell.execute_reply": "2024-07-12T03:18:51.833353Z",
     "shell.execute_reply.started": "2024-07-12T03:18:50.307719Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-12 03:18:51--  https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/documents.json\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 658332 (643K) [text/plain]\n",
      "Saving to: ‘documents.json’\n",
      "\n",
      "documents.json      100%[===================>] 642.90K  --.-KB/s    in 0.01s   \n",
      "\n",
      "2024-07-12 03:18:51 (44.1 MB/s) - ‘documents.json’ saved [658332/658332]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm -f documents.json\n",
    "!wget https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/documents.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T03:22:50.595663Z",
     "iopub.status.busy": "2024-07-12T03:22:50.595276Z",
     "iopub.status.idle": "2024-07-12T03:22:50.603065Z",
     "shell.execute_reply": "2024-07-12T03:22:50.602450Z",
     "shell.execute_reply.started": "2024-07-12T03:22:50.595639Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('documents.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T03:22:50.919910Z",
     "iopub.status.busy": "2024-07-12T03:22:50.919531Z",
     "iopub.status.idle": "2024-07-12T03:22:50.924939Z",
     "shell.execute_reply": "2024-07-12T03:22:50.924121Z",
     "shell.execute_reply.started": "2024-07-12T03:22:50.919882Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\", 'section': 'General course-related questions', 'question': 'Course - When will the course start?', 'course': 'data-engineering-zoomcamp'}\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)\n",
    "\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T03:22:51.640588Z",
     "iopub.status.busy": "2024-07-12T03:22:51.640204Z",
     "iopub.status.idle": "2024-07-12T03:22:51.644513Z",
     "shell.execute_reply": "2024-07-12T03:22:51.643566Z",
     "shell.execute_reply.started": "2024-07-12T03:22:51.640562Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T03:22:52.393871Z",
     "iopub.status.busy": "2024-07-12T03:22:52.393486Z",
     "iopub.status.idle": "2024-07-12T03:22:52.480709Z",
     "shell.execute_reply": "2024-07-12T03:22:52.479805Z",
     "shell.execute_reply.started": "2024-07-12T03:22:52.393847Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7f2fed95c4c0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The RAG Flow Cleaning and Modularizing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T03:22:56.395737Z",
     "iopub.status.busy": "2024-07-12T03:22:56.395348Z",
     "iopub.status.idle": "2024-07-12T03:22:56.399967Z",
     "shell.execute_reply": "2024-07-12T03:22:56.399083Z",
     "shell.execute_reply.started": "2024-07-12T03:22:56.395712Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course':'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=3\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T03:22:56.729800Z",
     "iopub.status.busy": "2024-07-12T03:22:56.729423Z",
     "iopub.status.idle": "2024-07-12T03:22:56.734668Z",
     "shell.execute_reply": "2024-07-12T03:22:56.733793Z",
     "shell.execute_reply.started": "2024-07-12T03:22:56.729773Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = '''\n",
    "    You are a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database. \n",
    "    Use only facts from the CONTEXT when answering the QUESTION.\n",
    "    If the CONTEXT doesn't contain the answer, output NONE\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    \n",
    "    CONTEXT: {context}\n",
    "    \n",
    "    '''.strip()\n",
    "\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T03:22:57.195964Z",
     "iopub.status.busy": "2024-07-12T03:22:57.195580Z",
     "iopub.status.idle": "2024-07-12T03:22:57.200561Z",
     "shell.execute_reply": "2024-07-12T03:22:57.199637Z",
     "shell.execute_reply.started": "2024-07-12T03:22:57.195939Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
    "    generated_ids = model.generate(**model_inputs, max_length=500)\n",
    "    result = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T03:22:57.682508Z",
     "iopub.status.busy": "2024-07-12T03:22:57.682124Z",
     "iopub.status.idle": "2024-07-12T03:22:57.686238Z",
     "shell.execute_reply": "2024-07-12T03:22:57.685578Z",
     "shell.execute_reply.started": "2024-07-12T03:22:57.682482Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    results = search(query)\n",
    "    builded_prompt = build_prompt(query, results)\n",
    "    answer = llm(builded_prompt)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T03:22:59.615202Z",
     "iopub.status.busy": "2024-07-12T03:22:59.614814Z",
     "iopub.status.idle": "2024-07-12T03:23:10.351553Z",
     "shell.execute_reply": "2024-07-12T03:23:10.350761Z",
     "shell.execute_reply.started": "2024-07-12T03:22:59.615178Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database. \n",
      "    Use only facts from the CONTEXT when answering the QUESTION.\n",
      "    If the CONTEXT doesn't contain the answer, output NONE\n",
      "    \n",
      "    QUESTION: the course has already started. Can I still join?\n",
      "    \n",
      "    CONTEXT: section: General course-related questions\n",
      "question: Course - Can I still join the course after the start date?\n",
      "answer: Yes, even if you don't register, you're still eligible to submit the homeworks.\n",
      "Be aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - When will the course start?\n",
      "answer: The purpose of this document is to capture frequently asked technical questions\n",
      "The exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\n",
      "Subscribe to course public Google Calendar (it works from Desktop only).\n",
      "Register before the course starts using this link.\n",
      "Join the course Telegram channel with announcements.\n",
      "Don’t forget to register in DataTalks.Club's Slack and join the channel.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - Can I follow the course after it finishes?\n",
      "answer: Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\n",
      "You can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - What is the course schedule?\n",
      "answer: The course schedule is available here.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - What is the course structure?\n",
      "answer: The course structure is available here.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - What is the course format?\n",
      "answer: The course format is available here.\n",
      "\n",
      "section: General course-related questions\n",
      "question: Course - What is the\n"
     ]
    }
   ],
   "source": [
    "query = \"the course has already started. Can I still join?\"\n",
    "print(rag(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
