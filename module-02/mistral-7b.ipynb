{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T02:36:59.861949Z",
     "iopub.status.busy": "2024-07-12T02:36:59.861585Z",
     "iopub.status.idle": "2024-07-12T02:37:01.197970Z",
     "shell.execute_reply": "2024-07-12T02:37:01.197246Z",
     "shell.execute_reply.started": "2024-07-12T02:36:59.861923Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-12 02:37:00--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3832 (3.7K) [text/plain]\n",
      "Saving to: ‘minsearch.py’\n",
      "\n",
      "minsearch.py        100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-07-12 02:37:01 (84.3 MB/s) - ‘minsearch.py’ saved [3832/3832]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm -f minsearch.py\n",
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T02:37:53.779322Z",
     "iopub.status.busy": "2024-07-12T02:37:53.778952Z",
     "iopub.status.idle": "2024-07-12T02:37:53.784721Z",
     "shell.execute_reply": "2024-07-12T02:37:53.783889Z",
     "shell.execute_reply.started": "2024-07-12T02:37:53.779297Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline \n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import json\n",
    "import minsearch\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-12T02:38:58.630650Z",
     "iopub.status.busy": "2024-07-12T02:38:58.630264Z",
     "iopub.status.idle": "2024-07-12T02:38:59.107215Z",
     "shell.execute_reply": "2024-07-12T02:38:59.106156Z",
     "shell.execute_reply.started": "2024-07-12T02:38:58.630624Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid token passed!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlogin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHF_TOKEN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/huggingface_hub/_login.py:111\u001b[0m, in \u001b[0;36mlogin\u001b[0;34m(token, add_to_git_credential, new_session, write_permission)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m add_to_git_credential:\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    106\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe token has not been saved to the git credentials helper. Pass \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`add_to_git_credential=True` in this function directly or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`--add-to-git-credential` if using via `huggingface-cli` if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou want to set the git credential as well.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         )\n\u001b[0;32m--> 111\u001b[0m     \u001b[43m_login\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_to_git_credential\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_to_git_credential\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrite_permission\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_permission\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_notebook():\n\u001b[1;32m    113\u001b[0m     notebook_login(new_session\u001b[38;5;241m=\u001b[39mnew_session, write_permission\u001b[38;5;241m=\u001b[39mwrite_permission)\n",
      "File \u001b[0;32m/opt/saturncloud/envs/saturn/lib/python3.9/site-packages/huggingface_hub/_login.py:307\u001b[0m, in \u001b[0;36m_login\u001b[0;34m(token, add_to_git_credential, write_permission)\u001b[0m\n\u001b[1;32m    305\u001b[0m permission \u001b[38;5;241m=\u001b[39m get_token_permission(token)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m permission \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid token passed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m write_permission \u001b[38;5;129;01mand\u001b[39;00m permission \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    310\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToken is valid but is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread-only\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m token is required.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlease provide a new token with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    311\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m correct permission.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    312\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid token passed!"
     ]
    }
   ],
   "source": [
    "login(token=os.environ['HF_TOKEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T06:15:08.735483Z",
     "iopub.status.busy": "2024-07-11T06:15:08.735159Z",
     "iopub.status.idle": "2024-07-11T06:15:55.707558Z",
     "shell.execute_reply": "2024-07-11T06:15:55.706772Z",
     "shell.execute_reply.started": "2024-07-11T06:15:08.735462Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b90d380ebee49699a69d45028f773df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3abde6d5a7e432780b02d6b2a05a684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8430b17e4684cdabbf43f8f7a25cc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7651d50c6f734806ae212d7dda9a0628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7aa976d24fa4a15ae28620138374c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9f746b50a34be0ab89dd1e25cdc40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/3.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16cb7c54e18f47fcb6ee3f39a0d729e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662a5c0ddc5544c0b5862c875b1fbb0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py:   0%|          | 0.00/73.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5220a7d78c814b44ab33d76234c01480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "602e495e50ab4f7d8a8dac1ab03747e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7953abbce8dd427f966d512b72785f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78bde56f5e242968dddea23ed977303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5688b6fb8d4d38bc54bddb5c2c9360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc019b128c60436bb805f8f091e2d4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\", paddig_side=\"left\") \n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-v0.1\", device_map=\"auto\", load_in_4bit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrivel and Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T06:16:04.224612Z",
     "iopub.status.busy": "2024-07-11T06:16:04.224235Z",
     "iopub.status.idle": "2024-07-11T06:16:05.619005Z",
     "shell.execute_reply": "2024-07-11T06:16:05.618191Z",
     "shell.execute_reply.started": "2024-07-11T06:16:04.224586Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-11 06:16:05--  https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/documents.json\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 658332 (643K) [text/plain]\n",
      "Saving to: ‘documents.json’\n",
      "\n",
      "documents.json      100%[===================>] 642.90K  --.-KB/s    in 0.008s  \n",
      "\n",
      "2024-07-11 06:16:05 (80.7 MB/s) - ‘documents.json’ saved [658332/658332]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm -f documents.json\n",
    "!wget https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/documents.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T06:16:07.029780Z",
     "iopub.status.busy": "2024-07-11T06:16:07.029368Z",
     "iopub.status.idle": "2024-07-11T06:16:07.037717Z",
     "shell.execute_reply": "2024-07-11T06:16:07.037116Z",
     "shell.execute_reply.started": "2024-07-11T06:16:07.029749Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('documents.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T06:16:07.394689Z",
     "iopub.status.busy": "2024-07-11T06:16:07.394299Z",
     "iopub.status.idle": "2024-07-11T06:16:07.399965Z",
     "shell.execute_reply": "2024-07-11T06:16:07.399153Z",
     "shell.execute_reply.started": "2024-07-11T06:16:07.394664Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\", 'section': 'General course-related questions', 'question': 'Course - When will the course start?', 'course': 'data-engineering-zoomcamp'}\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)\n",
    "\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T06:16:08.821291Z",
     "iopub.status.busy": "2024-07-11T06:16:08.820909Z",
     "iopub.status.idle": "2024-07-11T06:16:08.824982Z",
     "shell.execute_reply": "2024-07-11T06:16:08.824309Z",
     "shell.execute_reply.started": "2024-07-11T06:16:08.821264Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T06:16:09.269636Z",
     "iopub.status.busy": "2024-07-11T06:16:09.269237Z",
     "iopub.status.idle": "2024-07-11T06:16:09.361331Z",
     "shell.execute_reply": "2024-07-11T06:16:09.360576Z",
     "shell.execute_reply.started": "2024-07-11T06:16:09.269609Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7f289c29fe20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The RAG Flow Cleaning and Modularizing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T06:22:32.971870Z",
     "iopub.status.busy": "2024-07-11T06:22:32.971470Z",
     "iopub.status.idle": "2024-07-11T06:22:32.976276Z",
     "shell.execute_reply": "2024-07-11T06:22:32.975445Z",
     "shell.execute_reply.started": "2024-07-11T06:22:32.971846Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course':'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T06:22:33.971051Z",
     "iopub.status.busy": "2024-07-11T06:22:33.970624Z",
     "iopub.status.idle": "2024-07-11T06:22:33.975650Z",
     "shell.execute_reply": "2024-07-11T06:22:33.974745Z",
     "shell.execute_reply.started": "2024-07-11T06:22:33.971023Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = '''\n",
    "    You are a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database. \n",
    "    Use only facts from the CONTEXT when answering the QUESTION.\n",
    "    If the CONTEXT doesn't contain the answer, output NONE\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    \n",
    "    CONTEXT: {context}\n",
    "    \n",
    "    '''.strip()\n",
    "\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T06:23:49.007831Z",
     "iopub.status.busy": "2024-07-11T06:23:49.007439Z",
     "iopub.status.idle": "2024-07-11T06:23:49.012455Z",
     "shell.execute_reply": "2024-07-11T06:23:49.011776Z",
     "shell.execute_reply.started": "2024-07-11T06:23:49.007804Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    pipe = pipeline( \n",
    "        \"text-generation\", \n",
    "        model=model, \n",
    "        tokenizer=tokenizer, \n",
    "    )\n",
    "    \n",
    "    generation_args = { \n",
    "        \"max_new_tokens\": 500, \n",
    "        \"return_full_text\": False, \n",
    "        \"temperature\": 0.0, \n",
    "        \"do_sample\": False, \n",
    "    } \n",
    "    \n",
    "    messages = [ \n",
    "        {\"role\": \"user\", \"content\": query}, \n",
    "    ] \n",
    "\n",
    "    \n",
    "    output = pipe(messages, **generation_args)     \n",
    "    result = output[0]['generated_text']\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T06:23:49.988701Z",
     "iopub.status.busy": "2024-07-11T06:23:49.988309Z",
     "iopub.status.idle": "2024-07-11T06:23:49.992462Z",
     "shell.execute_reply": "2024-07-11T06:23:49.991762Z",
     "shell.execute_reply.started": "2024-07-11T06:23:49.988674Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    results = search(query)\n",
    "    builded_prompt = build_prompt(query, results)\n",
    "    answer = llm(builded_prompt)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T06:23:50.494255Z",
     "iopub.status.busy": "2024-07-11T06:23:50.493828Z",
     "iopub.status.idle": "2024-07-11T06:24:00.399578Z",
     "shell.execute_reply": "2024-07-11T06:24:00.398748Z",
     "shell.execute_reply.started": "2024-07-11T06:23:50.494226Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Yes, you can still join the course even if it has already started. Many courses offer a waiting list for those who are interested but missed the initial enrollment period. Here's what you can do:\n",
      "\n",
      "1. Check the course's website or contact the instructor to inquire about joining the waiting list.\n",
      "2. If the course has a waiting list, you can sign up for it and wait for a spot to open up.\n",
      "3. Some courses may also offer a second session or a catch-up option for those who missed the first session.\n",
      "4. Alternatively, you can look for similar courses or workshops that are currently accepting new participants.\n",
      "\n",
      "Remember to act quickly, as spots on waiting lists can fill up quickly. Good luck!\n"
     ]
    }
   ],
   "source": [
    "query = \"the course has already started. Can I still join?\"\n",
    "print(rag(query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
